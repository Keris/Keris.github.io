<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts | 杜利强</title>
    <link>https://keris.github.io/zh/post/</link>
      <atom:link href="https://keris.github.io/zh/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Posts</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>zh-Hans</language><lastBuildDate>Sun, 05 Apr 2020 19:40:58 +0800</lastBuildDate>
    <image>
      <url>https://keris.github.io/images/icon_hu0fc6cda6d9ee8f97aed5fca718c40606_62996_512x512_fill_lanczos_center_2.png</url>
      <title>Posts</title>
      <link>https://keris.github.io/zh/post/</link>
    </image>
    
    <item>
      <title>十元蛋炒饭</title>
      <link>https://keris.github.io/zh/post/shi-yuan-danchaofan/</link>
      <pubDate>Sun, 05 Apr 2020 19:40:58 +0800</pubDate>
      <guid>https://keris.github.io/zh/post/shi-yuan-danchaofan/</guid>
      <description>&lt;p&gt;随着逐步的复工，附近的餐馆陆续开始营业了，这使得我可以选择走出屋子上大街吃上一顿。早上喝了一碗牛奶泡燕麦，吃了一片土司面包，些许坚果和四个鸡蛋。所以到吃午饭时也不怎么饿，由于养成了按时吃饭的习惯，就还是出去吃，但心里暗地提示自己少吃一些。小区马路对面有好几家餐馆，另有一家便利店。而另一侧只有一家，提供新疆美食。我先是去了便利店，环顾一圈未发现引起胃口的什物便出了门。隔壁餐馆门外贴着菜单，看过一番之后，蛋炒饭入了我眼，并且只卖10块钱。其实，这家餐馆所有的饭都比较价廉。&lt;/p&gt;
&lt;p&gt;过了不一会儿蛋炒饭便好了，一个年纪五十左右的阿姨端到了我这边。我用勺子吃了几口，整体味道还算不错，但有的地方会发现比较咸。这份蛋炒饭除了米饭和鸡蛋，包含了黄瓜、胡萝卜和洋葱，并且份量中等，这十分对得起10块钱的价格，我寻思老板是不是在做公益，还是别的家赚取的太多。&lt;/p&gt;
&lt;p&gt;说起蛋炒饭，我最爱吃家里做的，我妈炒的。在家里只有在剩了饭才有机会做炒饭，并且不加鸡蛋。剩饭会和剩菜一起炒，这样炒出来往往比较油腻，但丝毫不影响饭的抢手和好吃。后来我想了想，其实要天天这样吃肯定也会腻。之所以我一直觉得家里的炒饭具有特别的味道，一个是西北的饮食习惯让我们以面食为主，米饭为辅，所以吃自家炒饭的机会不多；二是剩饭一般较少，做出来的炒饭就比较少，对于一家四口而言也就每人一小碗。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>硬币投掷模拟实验</title>
      <link>https://keris.github.io/zh/post/coin-toss-experiment/</link>
      <pubDate>Sat, 04 Apr 2020 17:53:27 +0800</pubDate>
      <guid>https://keris.github.io/zh/post/coin-toss-experiment/</guid>
      <description>&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import matplotlib.pyplot as plt
import numpy as np
import random
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;掷硬币模拟实验一&#34;&gt;掷硬币模拟实验一&lt;/h2&gt;
&lt;p&gt;假设一枚硬币落地后正面朝上的概率为$p$，进行$n$次投掷。通过模拟实验验证正面朝上的比例将随着投掷次数的增加越来越接近$p$。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 进行一次投掷，如果返回True则表示获得正面，否则反面
def make_a_toss(p):
    r = random.randint(1, 100)
    return r &amp;lt;= (100*p)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def simulate1(p, n=1000):
    heads = []
    count = 0
    for i in range(n):
        if make_a_toss(p):
            count += 1
        heads.append(count)
    x = np.array(range(1, n + 1))
    y = np.array(heads).astype(np.float32) / x
    plt.plot(x, y)
    plt.plot(x, np.ones(n) * p)
    plt.xlabel(&#39;The number of tosses&#39;)
    plt.ylabel(&#39;The proportion of heads&#39;)
    plt.title(f&#39;p = {p}&#39;)
    plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# p=0.3
simulate1(0.3)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_4_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# p=0.03
simulate1(.03, 10000)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_5_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;掷硬币模拟实验二&#34;&gt;掷硬币模拟实验二&lt;/h2&gt;
&lt;p&gt;假设一枚硬币落地后正面朝上的概率为$p$，进行$n$次投掷，定义$X$为正面朝上的次数。通过模拟实验验证$X$将随着实验次数的增加越来越接近$np$。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def moving_avg(x):
    result = np.array([.0] * len(x))
    s = 0
    for i, v in enumerate(x):
        s += v
        result[i] = s / (i + 1)
    return result
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def simulate2(p, n=1000):

    def one_experiment():
        heads = 0
        for i in range(n):
            if make_a_toss(p):
                heads += 1
        return heads

    heads = []
    for _ in range(1000): # do 1000 experiments
        heads.append(one_experiment())
    x = np.array(range(1, 1001))
    y = moving_avg(heads)
    plt.plot(x, y)
    plt.plot(x, np.ones(1000) * p * n)
    plt.xlabel(&#39;The number of experiments&#39;)
    plt.ylabel(&#39;The number of heads&#39;)
    plt.title(f&#39;p = {p}&#39;)
    plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# p=0.3, n=10
simulate2(0.3, 10)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_9_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# p=0.3, n=100
simulate2(0.3, 100)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_10_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# p=0.3, n=1000
simulate2(0.3, 1000)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_11_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>一个概率问题</title>
      <link>https://keris.github.io/zh/post/a-probability-problem/</link>
      <pubDate>Sat, 04 Apr 2020 13:02:41 +0800</pubDate>
      <guid>https://keris.github.io/zh/post/a-probability-problem/</guid>
      <description>&lt;p&gt;在开始之前我想说下这个配图，它是我今天早上拍的，里面是自己做的早餐，盘中是一个香蕉切了四小段，一片吐司面包和些许腰果，而旁边的碗中是牛奶泡燕麦。这样的搭配我已经吃了一周了，我已经感受到了积极的变化，而原先我都是不吃早餐或者在下地铁后顺路买一份麦当劳。&lt;/p&gt;
&lt;p&gt;现在我回到正题上。这个概率问题如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;有一个盒子，里面放了10个球，每个上面标了1到10之间的某个数字，现在进行3次有放回的抽取，问第一次的号小于第二次，第二次又小于第三次的概率是多少？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这个问题其实不难，我自认为智商中等偏下，这个题当我在面试时没有解出来😞。下面我回顾一下当初的情景。&lt;/p&gt;
&lt;p&gt;首先，我知道样本空间$\Omega$的大小为$|\Omega| = 10^3 = 1000$，如果我们将所求事件记为$A$，并且第$i$次抽取得到的号为$N_i(i=1,2,3)$，则$A = \{\omega = (N_1, N_2, N_3) \in \Omega: N_1 \lt N_2 \lt N_3\}$。现在要计算的是$|A|$，即事件$A$包含了多少个点？&lt;/p&gt;
&lt;p&gt;我采取逐个数的策略，但不是那么容易。$N_1$可以取1到8之间的数字，然后再考虑$N_2$的取值，最后是$N_3$。&lt;/p&gt;
&lt;p&gt;$N_1 = 1$的情况:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;    1
   /  \
  2 ... 9
 /  \    \
3 ... 10  10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;以上示意图中，每一层表示$N_i(i=1,2,3)$的取值，最后要计算的是叶子节点的数目。
容易计算当$N_1 = 1$时，共有$8 + 7 + \cdots + 1 = \frac{8 \cdot (8 + 1)}{2} = 36$个叶子结点。&lt;/p&gt;
&lt;p&gt;类似地，&lt;/p&gt;
&lt;p&gt;$N_1=2$时，有$7 + \cdots + 1 = \frac{7 \cdot (7 + 1)}{2} = 28$，&lt;/p&gt;
&lt;p&gt;&amp;hellip;&lt;/p&gt;
&lt;p&gt;$N_1=8$时，有$1$。&lt;/p&gt;
&lt;p&gt;最后的答案是$|A| = 36 + 28 + 21 + 15 + 10 + 6 + 3 + 1 = 120$，所以所求概率为$P = \frac{|A|}{|\Omega|} = \frac{120}{1000} = .12$。&lt;/p&gt;
&lt;p&gt;以上答案我在当时的情景下限于时间以及有些许紧张也没有给出😞。&lt;/p&gt;
&lt;p&gt;当时我还有个想法就是使用程序的方法进行计数：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;count = 0
for i in range(1, 9): # N1
  for j in range(i+1, 11): # N2
    for k in range(j+1, 11): # N3
      count += 1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;以上结果也会给出正确的结果即120。这个想法在当时考虑到切屏会有不好的影响，没有实行。&lt;/p&gt;
&lt;p&gt;后来一细想，以上两种方法都不是最优的，再三思考之后得到了最佳方法。看来自己脑子不好使了，对概率求解生疏也是原因。&lt;/p&gt;
&lt;p&gt;下面说说怎么最优求解。&lt;/p&gt;
&lt;p&gt;事件$A$中三个数都不同，从10个数连续3次取不同共有$10 \cdot 9 \cdot 8 = 720$，但是我们需要$N_1 \lt N_2 \lt N_3$，而三个数的排列共有$3! = 6$种，其中只有一种满足要求，所以$|A| = \frac{720}{6} = 120$。&lt;/p&gt;
&lt;p&gt;至此，问题求解完毕。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>先手优势</title>
      <link>https://keris.github.io/zh/post/xianshou-throwing/</link>
      <pubDate>Tue, 24 Mar 2020 14:00:50 +0800</pubDate>
      <guid>https://keris.github.io/zh/post/xianshou-throwing/</guid>
      <description>&lt;p&gt;棋经有云，“宁失一子，勿失一先”，可见先手的好处所在。为了建立对先手直观的理解，我们来玩一个游戏：&lt;/p&gt;
&lt;p&gt;&lt;em&gt;两个人玩投掷硬币的游戏，先掷出正面的人获胜，那么你是选择先掷还是后掷？&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;数学解法&#34;&gt;数学解法&lt;/h2&gt;
&lt;p&gt;假设硬币是公平的，即出现正面和反面的概率一样，均为&lt;code&gt;1/2&lt;/code&gt;。那么，在先手下获胜的情况是第&lt;code&gt;n&lt;/code&gt;次掷得正面，前&lt;code&gt;n-1&lt;/code&gt;次都为反面，其中&lt;code&gt;n&lt;/code&gt;为奇数。所以先手获胜的概率为&lt;/p&gt;
&lt;p&gt;$$p(\text{win}|\text{first}) = \sum_{k=0}^{\infty}(\frac{1}{2})^{2k + 1} = \frac{2}{3}$$&lt;/p&gt;
&lt;p&gt;相反，在后手下获胜的情况是第&lt;code&gt;n&lt;/code&gt;次掷得正面，前&lt;code&gt;n-1&lt;/code&gt;次均为反面，其中&lt;code&gt;n&lt;/code&gt;为偶数。所以，后手获胜的概率为&lt;/p&gt;
&lt;p&gt;$$p(\text{win}|\text{second}) = \sum_{k=1}^{\infty}(\frac{1}{2})^{2k} = \frac{1}{3}$$&lt;/p&gt;
&lt;p&gt;可以发现，先手获胜的概率为2/3，而后手获胜的概率为1/3，这告诉我们在生活中抓住先机，主动出击往往更能取得胜利。&lt;/p&gt;
&lt;h2 id=&#34;模拟法&#34;&gt;模拟法&lt;/h2&gt;
&lt;p&gt;前面我们用数学的方法进行了求解，下面来看看如何用程序来模拟，为此我写了一个Python程序：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# coding: utf-8
# filename: code.py
# Author: Liqiang Du &amp;lt;keris.du@gmail.com&amp;gt;
import random
import numpy as np


def simulate(n_games):
    &amp;quot;&amp;quot;&amp;quot;
    Simulate coin throwing game, the game is over when head appears.

    Args:
        n_games (int): the number of games.

    Returns:
        tuple: the first is the probability of win when first play,
        and the second the probability of win when second play.
    &amp;quot;&amp;quot;&amp;quot;
    win_count = np.array([0, 0])
    for i in range(n_games):
        game_over = False
        n_tails = 0
        while not game_over:
            x = random.randint(0, 1)  # 1 indicates head and 0 tail
            if x == 1:
                game_over = True
            else:
                n_tails += 1
        win_count[n_tails % 2] += 1
    return win_count.astype(float) / n_games


if __name__ == &amp;quot;__main__&amp;quot;:
    n_games = 100000
    probs = simulate(n_games)
    print(probs)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;程序的核心部分在于&lt;code&gt;simulate&lt;/code&gt;，每次游戏，出现正面游戏就结束，同时记录反面出现的次数，如果该次数为偶数，则先手为赢，否则后手为赢。最后程序返回一个元祖，第一个表示先手获胜的概率，第二个为后手获胜的概率。&lt;/p&gt;
&lt;p&gt;我们运行一下程序看看结果：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ python code.py
[0.66436 0.33564]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们模拟了10万次游戏，程序返回的结果跟数学求解结果十分接近。&lt;/p&gt;
&lt;p&gt;至此文章就完了。在这里我通过一个简单的游戏说明了先手的好处，这告诉我们一个道理，主动出击获得先手优势往往更能够成功。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>随机数生成</title>
      <link>https://keris.github.io/zh/post/random-number-generator/</link>
      <pubDate>Wed, 18 Mar 2020 11:45:54 +0800</pubDate>
      <guid>https://keris.github.io/zh/post/random-number-generator/</guid>
      <description>&lt;p&gt;最近参加了一家公司的面试，其中一个问题是：“如何在C语言中生成一个真随机数？” 我当时想到的答案是使用&lt;code&gt;rand()&lt;/code&gt;，但&lt;code&gt;rand()&lt;/code&gt;返回的其实是一个伪随机数，值的范围是&lt;code&gt;[0, RAND_MAX]&lt;/code&gt;。其中，&lt;code&gt;RAND_MAX&lt;/code&gt;跟具体的实现有关，也就是说在不同的实现中可能有不同的值。&lt;/p&gt;
&lt;p&gt;以上便是这篇博客的背景，也可以看出自己对随机数生成（RNG）掌握的也不全面，所以试图通过此文弥补一下短板。&lt;/p&gt;
&lt;h2 id=&#34;随机数的应用&#34;&gt;随机数的应用&lt;/h2&gt;
&lt;p&gt;随机数的应用有很多方面，包括赌博，统计采样，计算机仿真，加密等。&lt;/p&gt;
&lt;h2 id=&#34;真随机数与伪随机数&#34;&gt;真随机数与伪随机数&lt;/h2&gt;
&lt;p&gt;简单来讲，真随机数无法预测，而伪随机数在知道种子值后便能复现。我们先来了解一下生成随机数的两种方法。&lt;/p&gt;
&lt;p&gt;在第一种方法中，我们测量某个被认为是随机的物理现象，然后补偿测量过程中可能的偏差。这种随机源包括空气噪声，热噪声以及其他外部的电磁和量子现象。要产生一个随机数，我们需要获取足够的墒（entropy），但获取速率取决于被测量的物理现象。因此，这种产生随机数的方法是阻塞的（blocking）的，速率受限的。举个例子，在大部分Linux发行版中，伪随机设备文件&lt;code&gt;/dev/random&lt;/code&gt;就会阻塞直到从环境获取到足够的墒。由于这种阻塞行为，从&lt;code&gt;/dev/random&lt;/code&gt;大批量读以便用随机位填充磁盘经常会很慢，就是因为墒源是阻塞型的。&lt;/p&gt;
&lt;p&gt;在第二种方法中，我们使用计算的方法来生成明显随机值组成的长序列，但实际上结果完全由一个较短的初始值确定，这个初始值也叫种子值。因此，整个看似随机的序列在知道种子值的情况下能够被复现。相比第一种方法，第二种方法是非阻塞（non-blocking）的，所以其生成速率不受外部事件的影响。&lt;/p&gt;
&lt;p&gt;在实际应用中，一些系统采取混合的办法，即在可用的时候采用自然源提供的随机性，否则使用周期性重新设置种子、软件基于的密码安全的伪随机数生成器（CSPRNGs）。&lt;/p&gt;
&lt;p&gt;在这里小结一下：真随机数依赖于收集自然发生的墒，有了足够的墒方可生成随机数，因此是阻塞的，速率有限的；伪随机数使用计算方法产生，在知道种子值后能够复现，非阻塞，速率不受限。&lt;/p&gt;
&lt;h2 id=&#34;c语言中的随机数生成&#34;&gt;C语言中的随机数生成&lt;/h2&gt;
&lt;p&gt;在C语言中，标准库&lt;code&gt;stdlib.h&lt;/code&gt;提供了两个函数&lt;code&gt;int rand(void)&lt;/code&gt;和&lt;code&gt;void srand(unsigned)&lt;/code&gt;来帮助我们生成伪随机数。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;rand()&lt;/code&gt;返回一个位于区间&lt;code&gt;[0, RAND_MAX]&lt;/code&gt;的整数，&lt;code&gt;RAND_MAX&lt;/code&gt;在不同的实现中可能不同，但被保证至少是&lt;code&gt;32767&lt;/code&gt;。在调用&lt;code&gt;rand()&lt;/code&gt;前，如果我们不设置种子，系统默认我们设置种子为1，即调用了&lt;code&gt;srand(1)&lt;/code&gt;，在这种情况下，我们每次运行将会产生同样的值，下面看一个例子：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;

int main() {
    int num = rand();
    printf(&amp;quot;Random number: %d\n&amp;quot;, num);
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们编译以上代码并运行5次：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ gcc gen_rand.c &amp;amp;&amp;amp; for i in `seq 1 5`;do ./a.out;done
Random number: 16807
Random number: 16807
Random number: 16807
Random number: 16807
Random number: 16807
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到，程序在每次运行时均生成了同样的值，这是因为种子值均为1。&lt;/p&gt;
&lt;p&gt;接下来，我们再看看手动设置种子的情况：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;time.h&amp;gt;

int main() {
    srand((unsigned)time(0)); // use current time as seed
    int num = rand();
    printf(&amp;quot;Random number: %d\n&amp;quot;, num);
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这一次，我们将种子设为当前时间。同样地，我们编译并运行5次：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ gcc gen_rand1.c &amp;amp;&amp;amp; for i in `seq 1 5`;do ./a.out;done
Random number: 7890298
Random number: 7890298
Random number: 7890298
Random number: 7890298
Random number: 7890298
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;结果看似跟前面没有不同，因为5次调用依然生成了同样的值。其实，这个差别很细微，我们将种子设为当前时间，但只有在重新编译时才能有不同的种子值。因此，两次编译之间生成的值应该不同：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ gcc gen_rand1.c &amp;amp;&amp;amp; ./a.out
Random number: 12713907
$ gcc gen_rand1.c &amp;amp;&amp;amp; ./a.out
Random number: 12747521
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;c中的随机数生成&#34;&gt;C++中的随机数生成&lt;/h2&gt;
&lt;p&gt;在C++中，我们仍然可以使用&lt;code&gt;rand()&lt;/code&gt;和&lt;code&gt;srand()&lt;/code&gt;来生成随机数，但这已经不是标准推荐的做法，相反我们应该使用&lt;code&gt;random&lt;/code&gt;库提供的工具类来生成随机数。&lt;/p&gt;
&lt;p&gt;下面给出C++版本的代码，运行结果跟C语言别无二致，不再赘述。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;cstdlib&amp;gt;
#include &amp;lt;ctime&amp;gt;

using namespace std;

int main() {
    // srand((unsigned)time(nullptr)); // use current time as seed
    int r = rand();
    cout &amp;lt;&amp;lt; &amp;quot;Random number between 0 and &amp;quot; &amp;lt;&amp;lt; RAND_MAX &amp;lt;&amp;lt; &amp;quot; :&amp;quot;;
    cout &amp;lt;&amp;lt; r &amp;lt;&amp;lt; &#39;\n&#39;;
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;接下来，我们使用&lt;code&gt;random&lt;/code&gt;库提供的工具来生成随机数。&lt;code&gt;random&lt;/code&gt;库提供了两种类型的类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;均匀分布随机位生成器（URBGs），既包括伪随机数生成和真随机数生成（如果可用）&lt;/li&gt;
&lt;li&gt;随机数分布&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;详细的信息请参见 &lt;a href=&#34;https://en.cppreference.com/w/cpp/numeric/random&#34;&gt;https://en.cppreference.com/w/cpp/numeric/random&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;下面给出一个使用随机数引擎生成随机数的例子：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;random&amp;gt;

using namespace std;

int main() {
    random_device rd;
    default_random_engine e1(rd());
    cout &amp;lt;&amp;lt; e1() &amp;lt;&amp;lt; endl;
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们编译以上代码，并运行5次：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ g++ main.cc -std=c++17 &amp;amp;&amp;amp; for i in `seq 1 5`;do ./a.out;done
17429349
872858569
1540494345
40333012
95212997
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;从这里可以看到，我们编译代码一次，多次运行，每次会产生不同的值，序列变得不可预测。&lt;/p&gt;
&lt;p&gt;此外，我们可以将生成的随机数转换到某个闭区间的均匀分布或者正态分布，下面是一个均匀分布的例子：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;iomanip&amp;gt;
#include &amp;lt;string&amp;gt;
#include &amp;lt;random&amp;gt;
#include &amp;lt;map&amp;gt;

using namespace std;

int main() {
    random_device rd;
    default_random_engine e1(rd());
    uniform_int_distribution&amp;lt;int&amp;gt; dis(1, 6);
    cout &amp;lt;&amp;lt; dis.min() &amp;lt;&amp;lt; endl;
    cout &amp;lt;&amp;lt; dis.max() &amp;lt;&amp;lt; endl;
    map&amp;lt;int, int&amp;gt; hist;
    for (int i = 0; i != 10000; i++) {
        hist[dis(e1)]++;
    }
    for (auto[num, count] : hist) {
        cout &amp;lt;&amp;lt; num &amp;lt;&amp;lt; &#39; &#39; &amp;lt;&amp;lt; string(count / 200, &#39;*&#39;) &amp;lt;&amp;lt; &#39;\n&#39;;
    }
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;编译以上代码并运行，结果如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ g++ -std=c++17 main.cc &amp;amp;&amp;amp; ./a.out
1
6
1 ********
2 ********
3 *******
4 ********
5 ********
6 ********
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们来分析一下。首先，我们输出均匀分布可能生成的最小值和最大值，由于我们考虑的是闭区间&lt;code&gt;[1, 6]&lt;/code&gt;上的均匀分布，显然最小值和最大值分别为1和6。然后我们将产生的随机数转换到区间上的某个值，并统计出现次数。最后，我们绘制直方图，从结果来看，每个值出现的次数基本一样多（我们进行了10000次实验！）。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>一个例子导向的对变参模版的理解</title>
      <link>https://keris.github.io/zh/post/variadic-template/</link>
      <pubDate>Tue, 17 Mar 2020 10:13:02 +0800</pubDate>
      <guid>https://keris.github.io/zh/post/variadic-template/</guid>
      <description>&lt;p&gt;最近看C++编程语言第四版&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;，阅读到线程这一章，作者在讲解mutex时给出了一个例子，自己照着写了一个发现跑不通，研究后发现对变参模版理解不够，便写了这篇文章。&lt;/p&gt;
&lt;p&gt;首先，我们看看书本上的例子：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;mutex cout_mutex;

template&amp;lt;typename Arg, typename... Args&amp;gt;
void write(Arg a, Args... tail) {
    cout_mutex.lock();
    cout &amp;lt;&amp;lt; a;
    write(tail...);
    cout_mutex.unlock();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这个例子旨在说明deadlock，因为我们在&lt;code&gt;write&lt;/code&gt;函数中递归调用它，而该函数在进行输出前需要获取互斥变量。为了解除死锁，我们可以使用&lt;code&gt;recursive_mutex&lt;/code&gt;，这种类型的mutex允许递归地获取。&lt;/p&gt;
&lt;p&gt;基于以上想法，我写了一个例子来进行测试：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;mutex&amp;gt;

using namespace std;

recursive_mutex cout_mutex;

template&amp;lt;typename Arg, typename... Args&amp;gt;
void write(Arg a, Args... tail) {
    cout_mutex.lock();
    cout &amp;lt;&amp;lt; a;
    write(tail...);
    cout_mutex.unlock();
}

int main(int argc, char* argv[]) {
    write(&amp;quot;hello,&amp;quot;, &amp;quot;world&amp;quot;);
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;当我尝试编译以上代码却发现报出错误：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;$ g++ test.cc -std=c++17
test.cpp:12:6: error: no matching function for call to &#39;write&#39;
     write(tail...);
     ^~~~~
test.cpp:12:6: note: in instantiation of function template
      specialization &#39;write&amp;lt;const char *&amp;gt;&#39; requested here
test.cpp:17:6: note: in instantiation of function template
      specialization &#39;write&amp;lt;const char *, const char *&amp;gt;&#39; requested here
     write(&amp;quot;hello,&amp;quot;, &amp;quot;world&amp;quot;);
     ^
test.cpp:9:7: note: candidate function template not viable: requires at
      least argument &#39;a&#39;, but no arguments were provided
 void write(Arg a, Args... tail) {
      ^
1 error generated.
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;在编译时我使用了c++17标准。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;可以看到，编译器报告了一个错误，&lt;strong&gt;对&amp;rsquo;write&#39;的调用没有匹配的函数&lt;/strong&gt;，这是为何？&lt;/p&gt;
&lt;p&gt;对于以上的实现，&lt;code&gt;write(&amp;quot;hello,&amp;quot;, &amp;quot;world&amp;quot;)&lt;/code&gt;可以拆分成：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;输出&lt;code&gt;hello,&lt;/code&gt;，此时tail包含一个参数即&lt;code&gt;world&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;输出&lt;code&gt;world&lt;/code&gt;，此时tail为空，但write函数至少需要一个参数，所以产生以上错误。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;下面我们增加一个接受空参数的write函数来验证：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;mutex&amp;gt;

using namespace std;

recursive_mutex cout_mutex;

void write() {
    cout &amp;lt;&amp;lt; &amp;quot;&amp;quot;; // output nothing
}

template&amp;lt;typename Arg, typename... Args&amp;gt;
void write(Arg a, Args... tail) {
    cout_mutex.lock();
    cout &amp;lt;&amp;lt; a;
    write(tail...);
    cout_mutex.unlock();
}


int main(int argc, char* argv[]) {
    write(&amp;quot;hello,&amp;quot;, &amp;quot;world&amp;quot;);
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在进行上述操作后，代码编译通过，运行后输出以下结果：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;$ ./a.out
$ hello,world
&lt;/code&gt;&lt;/pre&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;英文名为：&lt;a href=&#34;https://www.amazon.com/dp/0321958322/ref=cm_sw_em_r_mt_dp_U_xP11DbJ5REYKZ&#34;&gt;The C++ Programming Language, 4th Edition&lt;/a&gt;. 作者为Bjarne Stroustrup. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>机器学习模型选择</title>
      <link>https://keris.github.io/zh/post/model-selection/</link>
      <pubDate>Fri, 13 Mar 2020 19:14:06 +0800</pubDate>
      <guid>https://keris.github.io/zh/post/model-selection/</guid>
      <description>&lt;h2&gt;目录&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#两种类型的错误&#34;&gt;两种类型的错误&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#模型复杂图&#34;&gt;模型复杂图&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#k折交叉验证&#34;&gt;K折交叉验证&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#学习曲线&#34;&gt;学习曲线&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;h3 id=&#34;两种类型的错误&#34;&gt;两种类型的错误&lt;/h3&gt;
&lt;p&gt;在选择模型时我们可能犯两种类型的错误，选择过于简单的模型或者过于复杂的模型，前者对应&lt;strong&gt;欠拟合&lt;/strong&gt;，后者对应&lt;strong&gt;过拟合&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;欠拟合发生时，模型具有高偏差（high bias），模型不能很好地拟合训练集；过拟合发生时，模型具有高方差（high variance），模型试图对训练数据进行记忆而不是学习其特点，在训练集上表现很好，但在测试集上表现很差。&lt;/p&gt;
&lt;p&gt;下面我们看一个欠拟合的例子：&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;underfitting.png&#34; &gt;
&lt;img data-src=&#34;underfitting.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;在这个例子中，左边的模型使用一个二次曲线去拟合数据点，而右边则是使用直线去拟合，可以发现直线并不能很好地拟合数据，这就是欠拟合的情形。&lt;/p&gt;
&lt;p&gt;了解了欠拟合，我们来看一个过拟合的例子：&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;overfitting.png&#34; data-caption=&#34;Overfitting&#34;&gt;
&lt;img data-src=&#34;overfitting.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Overfitting
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;在这个例子中，左边的模型使用一个二次曲线去拟合数据点，而右边的模型试图对训练集进行记忆，因而它在训练集上表现很好，但它没有学习到数据的良好属性以很好地泛化到测试集，这就是过拟合的情形。&lt;/p&gt;
&lt;p&gt;前面两个例子属于回归模型，在分类模型中我们也会看到欠拟合和过拟合。&lt;/p&gt;
&lt;p&gt;分类模型中的欠拟合：&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;underfitting-classification.png&#34; data-caption=&#34;Underfitting in a Classification Model&#34;&gt;
&lt;img data-src=&#34;underfitting-classification.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Underfitting in a Classification Model
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;分类模型中的过拟合：&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;overfitting-classification.png&#34; data-caption=&#34;Overfitting in a Classification Model&#34;&gt;
&lt;img data-src=&#34;overfitting-classification.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Overfitting in a Classification Model
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;最后，我们总结一下：&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;tradeoff-high-bias-high-variance.png&#34; data-caption=&#34;Tradeoff between High Bias and High Variance&#34;&gt;
&lt;img data-src=&#34;tradeoff-high-bias-high-variance.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Tradeoff between High Bias and High Variance
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h3 id=&#34;模型复杂图&#34;&gt;模型复杂图&lt;/h3&gt;
&lt;p&gt;在前面一部分，我们学习了欠拟合和过拟合，在这一部分，我们了解一下模型复杂图，即评估指标随着模型复杂性的提升如何变化。&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;model-complexity-graph.png&#34; data-caption=&#34;Model Complexity Graph&#34;&gt;
&lt;img data-src=&#34;model-complexity-graph.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Model Complexity Graph
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;在上面这个图中，左侧对应欠拟合的情形，此时模型在训练集和验证集上都具有较大的误差；右侧对应过拟合的情形，模型在训练集上具有较小的误差，而在验证集上具有较大的误差；圈起来的那个地方对应刚刚好的情形，此时模型在训练集和验证集上都具有较小的误差，过了这个点，在训练集上的误差持续减小，但在验证集上的误差开始不断变大。&lt;/p&gt;
&lt;p&gt;可能你注意到了一个新概念，&lt;strong&gt;验证集&lt;/strong&gt;，为什么不用测试集？&lt;/p&gt;
&lt;p&gt;在构建机器学习模型时，一个务必要坚持的原则是&lt;strong&gt;测试集只能用于最后的模型评估，而不能参与模型训练&lt;/strong&gt;。那么我们怎么选择一个好的模型，验证集即用于此目的。&lt;/p&gt;
&lt;p&gt;那怎么得到验证集？下图可以给你一个直观的理解：&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;cross-validation.png&#34; data-caption=&#34;Cross Validation&#34;&gt;
&lt;img data-src=&#34;cross-validation.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Cross Validation
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;可以看到，训练集中的一小部分被用来作为验证集，借助验证集我们评估模型是否欠拟合，过拟合或者刚刚好，即验证集用来进行决策，帮助我们选择一个好的模型。最后，测试集用于最终的模型评估。&lt;/p&gt;
&lt;h3 id=&#34;k折交叉验证&#34;&gt;K折交叉验证&lt;/h3&gt;
&lt;p&gt;可能你注意到了，由于从训练集中划出了一小部分作为验证集，这使得训练数据变少了，这会对模型产生不利因素，为此你需要使用K折交叉验证。&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;k-fold-1.png&#34; &gt;
&lt;img data-src=&#34;k-fold-1.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;在上面这个图中，我们有12个样本，其中实心的用于训练，空心的用于测试&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;。这是一个4折交叉验证，每次其中一折用于测试，剩余三折用于训练。第一次，第一折样本&lt;code&gt;[0,1,2]&lt;/code&gt;用于测试；第二次，第二折样本&lt;code&gt;[3,4,5]&lt;/code&gt;用于测试；第三次，第三折样本&lt;code&gt;[6,7,8]&lt;/code&gt;用于测试；最后一次，最后一折样本&lt;code&gt;[9,10,11]&lt;/code&gt;用于测试。 可以看到，经过4折交叉验证，&lt;strong&gt;训练集中的所有样本都参与了模型训练&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;接下来，我们看看如何在&lt;code&gt;sklearn&lt;/code&gt;中进行K折交叉验证：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np
from sklearn.model_selection import KFold
kf = KFold(4)
X = np.arange(12)
for train_indices, test_indices in kf.split(X):
    print(train_indices, test_indices)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;以上代码产生如下结果：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[ 3  4  5  6  7  8  9 10 11] [0 1 2]
[ 0  1  2  6  7  8  9 10 11] [3 4 5]
[ 0  1  2  3  4  5  9 10 11] [6 7 8]
[0 1 2 3 4 5 6 7 8] [ 9 10 11]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到，输出结果跟图中的例子完全一致。可能你也注意到了，在这个例子中，每一折都是顺序产生，其实我们可以进行随机选取。&lt;/p&gt;
&lt;p&gt;












&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;k-fold-2.png&#34; &gt;
&lt;img data-src=&#34;k-fold-2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;



&lt;/figure&gt;

同样地，我们看看在&lt;code&gt;sklearn&lt;/code&gt;中如何做：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np
from sklearn.model_selection import KFold
kf = KFold(4, shuffle=True)
X = np.arange(12)
for train_indices, test_indices in kf.split(X):
    print(train_indices, test_indices)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;以上代码的结果如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[0 1 2 3 4 6 7 8 9] [ 5 10 11]
[ 0  1  2  4  5  6  7 10 11] [3 8 9]
[ 0  1  3  4  5  8  9 10 11] [2 6 7]
[ 2  3  5  6  7  8  9 10 11] [0 1 4]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到，每一折中的样本不再连续，而是随机抽取的。&lt;/p&gt;
&lt;h3 id=&#34;学习曲线&#34;&gt;学习曲线&lt;/h3&gt;
&lt;p&gt;在模型的训练过程中，通过绘制训练误差和验证误差 vs. 参与训练的样本数，我们可以得到两条曲线。&lt;/p&gt;
&lt;p&gt;下面我们来看一个图：&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;learning-curves-1.png&#34; data-caption=&#34;Learning Curves&#34;&gt;
&lt;img data-src=&#34;learning-curves-1.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Learning Curves
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;图的左侧是一个高偏差的模型（&lt;em&gt;对应前述的线性模型&lt;/em&gt;），即模型欠拟合。在训练样本比较少时，模型能很好地拟合数据，因此训练误差很小，但当评估模型时，由于训练样本较少，模型的表现不会太好，因此验证误差会很大。随着参与训练的样本增加，更多的样本需要拟合，拟合难度增加，训练误差可能会增大一点。此时，由于使用了更多的训练数据，我们会得到一个稍微好点的模型，因此验证误差会减小一点，但不会太多。最后，当更多的数据加入训练，训练误差会增加一点，验证误差会减小一点，它们会越来越靠近。&lt;/p&gt;
&lt;p&gt;图的中间一个刚刚好的模型（&lt;em&gt;对应二次曲线模型&lt;/em&gt;）。跟前面描述的情况一样，随着参与训练的样本增加，训练误差会增加，验证误差会减小，最后它们会越来越接近，不同于左侧的情况，&lt;strong&gt;验证误差和训练误差会收敛到比较低的位置&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;图的右侧是一个高方差的模型（&lt;em&gt;对应高阶拟合模型&lt;/em&gt;），一开始的情况跟前面两个模型的情况一样，但随着参与训练的样本增加，训练误差会增加，但会比较小，因为此时的模型试图对训练集进行记忆，同时验证误差会减小，但会比较大。最后，&lt;strong&gt;验证误差和训练误差会收敛，但不会靠近&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;接下来，我们看一个具体的例子：&lt;/p&gt;
&lt;p&gt;样本包含两类数据，如下所示：&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;data-visualization.png&#34; data-caption=&#34;Scatter Plot of data&#34;&gt;
&lt;img data-src=&#34;data-visualization.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Scatter Plot of data
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;针对该数据，我们拟合以下三个模型，看看它们的学习曲线如何：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;逻辑回归模型&lt;/li&gt;
&lt;li&gt;决策树模型&lt;/li&gt;
&lt;li&gt;支持向量机模型&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import learning_curve
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.svm import SVC

# Load data
df = pd.read_csv(&#39;data.csv&#39;)
X = np.array(df[[&#39;x1&#39;, &#39;x2&#39;]])
y = np.array(df[&#39;y&#39;])

# Fix random seed
np.random.seed(55)

def randomize(X, Y):
    permutation = np.random.permutation(Y.shape[0])
    X2 = X[permutation,:]
    Y2 = Y[permutation]
    return X2, Y2

X2, y2 = randomize(X, y)

# Construct three models to draw learning curves
estimators = {}

# Logistic Regression
estimators[&#39;LR&#39;] = LogisticRegression()

# Decision Tree
estimators[&#39;DT&#39;] = GradientBoostingClassifier()

# Support Vector Machine
estimators[&#39;SVC&#39;] = SVC(kernel=&#39;rbf&#39;, gamma=1000)

plt.figure(figsize=(12, 6))

for i, m in enumerate(estimators):
    train_sizes, train_scores, test_scores = learning_curve(
        estimators[m], X2, y2, cv=None, n_jobs=1, train_sizes=np.linspace(.1, 1.0, 10))
    train_scores_mean = np.mean(train_scores, axis=1)
    # train_scores_std = np.std(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)
    # test_scores_std = np.std(test_scores, axis=1)

    plt.subplot(1, 3, i + 1)
    plt.grid()

    plt.title(&amp;quot;Learning Curves of {}&amp;quot;.format(m))
    plt.xlabel(&amp;quot;Training examples&amp;quot;)
    plt.ylabel(&amp;quot;Score&amp;quot;)

    plt.plot(train_scores_mean, &#39;o-&#39;, color=&amp;quot;g&amp;quot;,
             label=&amp;quot;Training score&amp;quot;)
    plt.plot(test_scores_mean, &#39;o-&#39;, color=&amp;quot;y&amp;quot;,
             label=&amp;quot;Cross-validation score&amp;quot;)


    plt.legend(loc=&amp;quot;best&amp;quot;)

plt.tight_layout()
plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;以上代码将生成三个模型的学习曲线，我们来看一看：&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;learning-curves.png&#34; &gt;
&lt;img data-src=&#34;learning-curves.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;根据这些曲线可以得出：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;逻辑回归模型的训练和测试得分很低。&lt;/li&gt;
&lt;li&gt;决策树模型的训练和测试得分很高。&lt;/li&gt;
&lt;li&gt;支持向量机模型的训练得分很高，测试得分很低&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此，决策树模型刚刚好，逻辑回归模型欠拟合，而支持向量机模型过拟合。&lt;/p&gt;
&lt;p&gt;同样，我们可以反转这些曲线（因为度量使用的是得分而不是误差）然后与下图进行对比。&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;learning-curves-2.png&#34; &gt;
&lt;img data-src=&#34;learning-curves-2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;最后，我们看一下在实际情况中是否也这样，为此我们绘制模型的边界曲线：&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;models-boundary.png&#34; &gt;
&lt;img data-src=&#34;models-boundary.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;我们可以看到：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;逻辑回归模型使用一条直线，这太简单了。在训练集上的效果不太好，因此欠拟合。&lt;/li&gt;
&lt;li&gt;决策树模型使用一个方形，拟合的很好，并能够泛化。因此，该模型效果很好。&lt;/li&gt;
&lt;li&gt;支持向量机模型实际上在每个点周围都画了一个小圆圈。它实际上是在记住训练集，无法泛化。因此，过拟合。&lt;/li&gt;
&lt;/ul&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;这里的测试实为验证，不同于最终的测试，后者指模型评估，前者为模型验证。 &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>评估指标</title>
      <link>https://keris.github.io/zh/post/metrics/</link>
      <pubDate>Wed, 11 Mar 2020 19:20:11 +0800</pubDate>
      <guid>https://keris.github.io/zh/post/metrics/</guid>
      <description>&lt;h2&gt;目录&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#混淆矩阵&#34;&gt;混淆矩阵&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#accuracy&#34;&gt;Accuracy&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#precision&#34;&gt;Precision&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#recall&#34;&gt;Recall&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#f1-score&#34;&gt;F1 score&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#f_beta-score&#34;&gt;$F_\beta$ score&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#roc-curve&#34;&gt;ROC Curve&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#auc&#34;&gt;AUC&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#回归指标&#34;&gt;回归指标&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;h2 id=&#34;混淆矩阵&#34;&gt;混淆矩阵&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;guessed positive&lt;/th&gt;
&lt;th&gt;guessed negative&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;positive&lt;/td&gt;
&lt;td&gt;true positives, #TP&lt;/td&gt;
&lt;td&gt;false negatives, #FN&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;negative&lt;/td&gt;
&lt;td&gt;false positives, #FP&lt;/td&gt;
&lt;td&gt;true negatives, #TN&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;假设某个模型在一组样本上的表现如下：&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;model-performance.png&#34; &gt;
&lt;img data-src=&#34;model-performance.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;其中，蓝色的点为正例（positives)，橙色的点为负例（negatives），则混淆矩阵如下：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;guessed positive&lt;/th&gt;
&lt;th&gt;guessed negative&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;positive&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;negative&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;accuracy&#34;&gt;Accuracy&lt;/h2&gt;
&lt;p&gt;Accuracy，也就是准确率，表示样本中分类正确所占的比例。&lt;/p&gt;
&lt;p&gt;$$\text{Accuracy} = \frac{\text{#TP} + \text{#TN}}{\text{#TP} + \text{#FP} + \text{#TN} + \text{#FN}}$$&lt;/p&gt;
&lt;p&gt;其中:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;#TP&lt;/code&gt;表示&lt;code&gt;true positive&lt;/code&gt;的数目&lt;/li&gt;
&lt;li&gt;&lt;code&gt;#FP&lt;/code&gt;表示&lt;code&gt;false positive&lt;/code&gt;的数目&lt;/li&gt;
&lt;li&gt;&lt;code&gt;#TN&lt;/code&gt;表示&lt;code&gt;true negative&lt;/code&gt;的数目&lt;/li&gt;
&lt;li&gt;&lt;code&gt;#FN&lt;/code&gt;表示&lt;code&gt;false negative&lt;/code&gt;的数目&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于图1中的模型，准确率计算如下：&lt;/p&gt;
&lt;p&gt;$$\text{Accuracy} = \frac{6 + 5}{6 + 1 + 5 + 2} = \frac{11}{14}= 78.57\%$$&lt;/p&gt;
&lt;p&gt;准确率在数据偏斜的情况下将不再适用。比如在下图所示的例子中：&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;credit-card-fraud.png&#34; &gt;
&lt;img data-src=&#34;credit-card-fraud.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;模型需要找出良好的交易，但我们的样本中绝大部分都是良好的交易，这导致无论我们的模型如何，它都具有很高的准确率，如图中所示为&lt;code&gt;99.83%&lt;/code&gt;！，此时准确率将不能够评估我们的模型。&lt;/p&gt;
&lt;h2 id=&#34;precision&#34;&gt;Precision&lt;/h2&gt;
&lt;p&gt;Precision即精度，表示在所有预测为正例的样本中有多少是真正例。&lt;/p&gt;
&lt;p&gt;$$\text{Precision} = \frac{\text{#TP}}{\text{#TP} + \text{#FP}}$$&lt;/p&gt;
&lt;p&gt;对于图1中的模型，精度计算如下：&lt;/p&gt;
&lt;p&gt;$$\text{Precision} = \frac{6}{6 + 2} = \frac{6}{8} = 75\%$$&lt;/p&gt;
&lt;h2 id=&#34;recall&#34;&gt;Recall&lt;/h2&gt;
&lt;p&gt;Recall即为召回率，所有的正例样本中真正例所占的比例：&lt;/p&gt;
&lt;p&gt;$$\text{Recall} = \frac{\text{#TP}}{\text{#TP} + \text{#FN}}$$&lt;/p&gt;
&lt;p&gt;对于图1中的模型，召回率计算如下：&lt;/p&gt;
&lt;p&gt;$$\text{Recall} = \frac{6}{6 + 1} = \frac{6}{7} = 85.71\%$$&lt;/p&gt;
&lt;h2 id=&#34;f1-score&#34;&gt;F1 score&lt;/h2&gt;
&lt;p&gt;F1-score定义如下：&lt;/p&gt;
&lt;p&gt;$$\text{F1} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$$&lt;/p&gt;
&lt;p&gt;可以看到F1-score综合了精度和召回率，为精度和召回率的调和平均：&lt;strong&gt;在召回率不变的条件下，精度越高，F1-score越大；在精度不变的条件下，召回率越高，F1-score越大&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;f_beta-score&#34;&gt;$F_\beta$ score&lt;/h2&gt;
&lt;p&gt;$F_\beta-\text{score}$定义为：&lt;/p&gt;
&lt;p&gt;$$F_\beta = (1 + \beta^2) \times \frac{\text{Precision} \times \text{Recall}}{\beta^2 \times \text{Precision} + \text{Recall}}$$&lt;/p&gt;
&lt;p&gt;可以看出来，当$\beta = 1$时即为F1 score。&lt;/p&gt;
&lt;p&gt;下面我们看下$F_\beta$随$\beta$变化的情况：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;当$\beta = 0$时，通过计算不难得出$F_0 = \text{Precision}$;&lt;/li&gt;
&lt;li&gt;相反，当$\beta$取很大的值时，$F_\beta$将趋近召回率。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;小结：当$\beta$取较小的值时，精度比召回率重要，如$F_{0.5}$ score；当$\beta$取较大值时召回率比精度重要，如$F_2$ score。&lt;/p&gt;
&lt;h2 id=&#34;roc-curve&#34;&gt;ROC Curve&lt;/h2&gt;
&lt;p&gt;ROC Curve的全称为Receiver Operating Characteristic Curve，即受试者工作特性缺陷，它刻画了模型在所有分类阈值下的表现。&lt;/p&gt;
&lt;p&gt;要绘制该曲线，我们需要计算以下两个参数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;True Positive Rate, TPR&lt;/li&gt;
&lt;li&gt;False Positive Rate, FPR&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;TPR，表示所有的正例样本中真正例的占比，不难发现，这其实跟召回率一个概念：&lt;/p&gt;
&lt;p&gt;$$\text{TPR} = \frac{\text{#TP}}{\text{#TP} + \text{#FN}}$$&lt;/p&gt;
&lt;p&gt;FPR，表示所有的负例样本中假正例的占比：&lt;/p&gt;
&lt;p&gt;$$\text{FPR} = \frac{\text{#FP}}{\text{#FP} + \text{#TN}}$$&lt;/p&gt;
&lt;p&gt;在不同的分类阈值下绘制TPR vs. FPR便得到ROC曲线：&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;ROCCurve.svg&#34; &gt;
&lt;img data-src=&#34;ROCCurve.svg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;



&lt;/figure&gt;

&lt;h2 id=&#34;auc&#34;&gt;AUC&lt;/h2&gt;
&lt;p&gt;AUC的全称为Area Under a ROC Curve，即ROC曲线下的面积。&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;AUC.png&#34; &gt;
&lt;img data-src=&#34;AUC.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;



&lt;/figure&gt;

&lt;h2 id=&#34;回归指标&#34;&gt;回归指标&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Mean Absolute Error (MAE)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;MAE即平均绝对误差，假设我们有一组样本${x_i, y_i}, i = 1, 2, \cdots, n$，模型的输出为$\text{preds} = [\hat{y}_1, \hat{y}_2, \cdots, \hat{y}_n]$，则MAE计算如下：&lt;/p&gt;
&lt;p&gt;$$\text{MAE} = \frac{1}{n}\sum_i^n |y_i - \hat{y}_i|$$&lt;/p&gt;
&lt;p&gt;借助&lt;code&gt;sklearn&lt;/code&gt;，我们可以很方便地计算MAE：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from sklearn.metrics import mean_absolute_error
from sklearn.linear_model import LinearRegression
clf = LinearRegression()
preds = clf.fit(X, y)
error = mean_absolute_error(y, preds)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;从公式来看，MAE不可导，使得不能采用梯度下降方法进行优化，此时我们可以借助均方误差。&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Mean Squared Error (MSE)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;MSE即均方误差，定义如下：&lt;/p&gt;
&lt;p&gt;$$\text{MSE} = \frac{1}{n}\sum_i^n (y_i - \hat{y}_i)^2$$&lt;/p&gt;
&lt;p&gt;同样地，MSE通过&lt;code&gt;sklearn&lt;/code&gt;可以很方便地进行计算：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from sklearn.metrics import mean_squared_error
from sklearn.linear_model import LinearRegression
clf = LinearRegression()
preds = clf.fit(X, y)
error = mean_squared_error(y, preds)
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;R2 Score&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;R2分数通过将现有的模型与最简单的可能模型相比得出。&lt;/p&gt;
&lt;p&gt;比如，我们要拟合一堆数据点，那最简单的可能模型是什么？那就是我们取所有值的平均值，然后画一条水平线。此时我们可以计算出这个模型的均方误差大于线性回归模型的均方误差，如下图所示：&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;r2.png&#34; &gt;
&lt;img data-src=&#34;r2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;R2分数定义为：&lt;/p&gt;
&lt;p&gt;$$\text{R2} = 1 - \frac{\text{MSE of 当前模型}}{\text{MSE of 最简单的可能模型}}$$&lt;/p&gt;
&lt;p&gt;以上图为例，分子为线性回归模型（右侧）的均方误差，分母为简单模型（左侧）的均方误差。&lt;/p&gt;
&lt;p&gt;由于最简单的可能模型的均方误差大于线性回归模型的均方误差，我们在相比之后得到一个0到1之间的数字，从而R2得分也是一个0到1之间的数，并且有以下结论：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;R2越接近0，我们的模型越接近最简单的可能模型，此时模型是一个bad model&lt;/li&gt;
&lt;li&gt;相反，R2越接近1，说明我们模型相比最简单的可能模型具有更小的均方误差，此时模型是一个good model&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在&lt;code&gt;sklearn&lt;/code&gt;中，我们如下计算R2得分：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; from sklearn.metrics import r2_score
&amp;gt;&amp;gt;&amp;gt; y_true = [1, 2, 4]
&amp;gt;&amp;gt;&amp;gt; y_pred = [1.3, 2.5, 3.7]
&amp;gt;&amp;gt;&amp;gt; r2_score(y_true, y_pred)
&amp;gt;&amp;gt;&amp;gt; 0.9078571428571429
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>信用评分卡模型</title>
      <link>https://keris.github.io/zh/post/credit-score-card/</link>
      <pubDate>Tue, 03 Mar 2020 17:28:08 +0800</pubDate>
      <guid>https://keris.github.io/zh/post/credit-score-card/</guid>
      <description>&lt;h2&gt;目录&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#信用评分卡模型&#34;&gt;信用评分卡模型&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#评分卡模型划分&#34;&gt;评分卡模型划分&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#如何利用评分卡对用户进行评分&#34;&gt;如何利用评分卡对用户进行评分？&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#小结&#34;&gt;小结&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#评分卡模型的开发&#34;&gt;评分卡模型的开发&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#评分卡模型开发流程&#34;&gt;评分卡模型开发流程&lt;/a&gt;
          &lt;ul&gt;
            &lt;li&gt;&lt;a href=&#34;#数据获取&#34;&gt;数据获取&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#eda&#34;&gt;EDA&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#数据预处理&#34;&gt;数据预处理&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#数据清洗&#34;&gt;数据清洗&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#变量分箱&#34;&gt;变量分箱&lt;/a&gt;
              &lt;ul&gt;
                &lt;li&gt;&lt;a href=&#34;#无监督分箱&#34;&gt;无监督分箱&lt;/a&gt;&lt;/li&gt;
                &lt;li&gt;&lt;a href=&#34;#有监督分箱&#34;&gt;有监督分箱&lt;/a&gt;&lt;/li&gt;
                &lt;li&gt;&lt;a href=&#34;#小结-1&#34;&gt;小结&lt;/a&gt;&lt;/li&gt;
              &lt;/ul&gt;
            &lt;/li&gt;
          &lt;/ul&gt;
        &lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;h2 id=&#34;信用评分卡模型&#34;&gt;信用评分卡模型&lt;/h2&gt;
&lt;p&gt;信用评分卡模型是一种最常见的金融风控手段。它是指根据客户的各种属性和行为数据构建一个信用评分模型，对客户进行信用评分，并据此决定是否给予授信以及授信的额度和利率，从而识别和减少在金融交易中存在的交易风险。&lt;/p&gt;
&lt;p&gt;以下为评分卡模型的示意图：&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;credit-score-card-demo.png&#34; data-caption=&#34;Credit Score Card Demo&#34;&gt;
&lt;img data-src=&#34;credit-score-card-demo.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;图&#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    Credit Score Card Demo
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h3 id=&#34;评分卡模型划分&#34;&gt;评分卡模型划分&lt;/h3&gt;
&lt;p&gt;在不同的业务阶段我们可以构建不同的评分卡模型。根据借贷时间，评分卡模型可以划分为以下三种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;贷前：申请评分卡（Application score card），又称为A卡&lt;/li&gt;
&lt;li&gt;贷中：行为评分卡（Behavior score card），又称为B卡&lt;/li&gt;
&lt;li&gt;贷后：催收评分卡（Collection score card），又称为C卡&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;如何利用评分卡对用户进行评分&#34;&gt;如何利用评分卡对用户进行评分？&lt;/h3&gt;
&lt;p&gt;一个用户的评分等于基准分加上对客户各个属性的评分。对前面给出的示意图中的例子而言：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;客户评分 = 基准分 + 年龄评分 + 性别评分 + 婚姻状况评分 + 学历评分 + 月收入评分
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;现有一客户，其年龄为27岁，性别男，已婚，本科学历，月收入为10k，那么他的评分为：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;223(基准分) + 8(年龄评分) + 4(性别评分) + 8(婚姻状况评分) + 8(学历评分) + 13(月收入评分) = 264
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;小结&#34;&gt;小结&lt;/h3&gt;
&lt;p&gt;以上就是评分卡模型的具体用法。在前面的例子中，不难发现以下三个问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如何选择用户的属性？&lt;/li&gt;
&lt;li&gt;评分卡模型采用的是对属性的分段进行评分，那么如何进行有效的分段？&lt;/li&gt;
&lt;li&gt;如何对每个分段进行评分？&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;评分卡模型的开发&#34;&gt;评分卡模型的开发&lt;/h2&gt;
&lt;h3 id=&#34;评分卡模型开发流程&#34;&gt;评分卡模型开发流程&lt;/h3&gt;
&lt;p&gt;信用评分卡模型的开发一般包括数据获取，EDA，数据预处理，变量筛选，模型开发及评估，生成评分卡模型，模型上线及监测。典型的开发流程图如下：&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;credit-score-card-flowchart.png&#34; data-caption=&#34;Credit Score Card Flowchart&#34;&gt;
&lt;img data-src=&#34;credit-score-card-flowchart.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;70%&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;图&#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    Credit Score Card Flowchart
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h4 id=&#34;数据获取&#34;&gt;数据获取&lt;/h4&gt;
&lt;p&gt;数据主要有两个来源：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;金融机构自有数据：如用户的年龄，户籍，性别，收入，负债比，在本机构的借款和还款行为等&lt;/li&gt;
&lt;li&gt;第三方数据：如用户在其他机构的借贷行为，用户的消费行为数据等&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;eda&#34;&gt;EDA&lt;/h4&gt;
&lt;p&gt;EDA为&lt;a href=&#34;https://en.wikipedia.org/wiki/Exploratory_data_analysis&#34;&gt;Exploratory Data Analysis&lt;/a&gt;的简写，即探索性数据分析。这个阶段旨在了解数据的主要特性，如字段的缺失情况，异常值情况，中位数，分布等。最后制定一个合理的数据预处理方案。&lt;/p&gt;
&lt;h4 id=&#34;数据预处理&#34;&gt;数据预处理&lt;/h4&gt;
&lt;p&gt;数据预处理主要包括数据清洗，变量分箱和WOE编码。&lt;/p&gt;
&lt;h4 id=&#34;数据清洗&#34;&gt;数据清洗&lt;/h4&gt;
&lt;p&gt;数据清洗主要是对数据中的缺失值和异常值进行处理。一般我们选择删除缺失率超过某个阈值&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;（如30%，50%等）的变量。&lt;/p&gt;
&lt;h4 id=&#34;变量分箱&#34;&gt;变量分箱&lt;/h4&gt;
&lt;p&gt;所谓的分箱定义如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对连续变量进行分段以离散化&lt;/li&gt;
&lt;li&gt;将离散变量的多个状态进行合并，减少离散变量的状态数&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;通过分箱操作，我们达到了对变量分段的目的。&lt;/p&gt;
&lt;p&gt;常见的分箱类型如下：&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;binning.png&#34; data-caption=&#34;常见的变量分箱类型&#34;&gt;
&lt;img data-src=&#34;binning.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;图&#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    常见的变量分箱类型
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h5 id=&#34;无监督分箱&#34;&gt;无监督分箱&lt;/h5&gt;
&lt;p&gt;无监督分箱主要包括三类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;等频分箱：把自变量的值按从小到大排序，将自变量的取值个数等分为&lt;code&gt;k&lt;/code&gt;部分，每部分作为一个分箱&lt;/li&gt;
&lt;li&gt;等距分箱：把自变量的值按从小到大排序，将自变量的取值范围分为&lt;code&gt;k&lt;/code&gt;个等距的区间，每个区间作为一个分箱&lt;/li&gt;
&lt;li&gt;聚类分箱：用&lt;code&gt;k-means&lt;/code&gt;等聚类法将自变量分为&lt;code&gt;k&lt;/code&gt;类，但需要在聚类过程中保证分箱的有序性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;小结：&lt;/strong&gt; 无监督分箱仅考虑了各个变量自身的结构，并没有考虑自变量与目标变量之间的关系，因此这种分箱方法不一定会带来模型性能的提升。&lt;/p&gt;
&lt;h5 id=&#34;有监督分箱&#34;&gt;有监督分箱&lt;/h5&gt;
&lt;p&gt;有监督分箱主要包括Split分箱和Merge分箱。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Split分箱是一种自上而下的分箱方法，其和决策树比较相似，切分点的选择指标主要有entropy， gini指数和IV值等。&lt;/li&gt;
&lt;li&gt;Merge分箱是一种自下而上的分箱方法，常见的merge分箱为ChiMerge分箱。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;ChiMerge分箱的基本思想是：&lt;em&gt;如果两个相邻区间具有相似的类分布，则合并它们，否则保持不变。ChiMerge通常采用卡方值来度量两相邻区间的类分布的相似性。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;计算卡方值的公式如下：&lt;/p&gt;
&lt;p&gt;$$
\chi^2 = \sum_{i=1}^2 \sum_{j=1}^k \frac{(A_{ij} - E_{ij})^2}{E_{ij}}
$$&lt;/p&gt;
&lt;p&gt;其中：&lt;/p&gt;
&lt;p&gt;$k =$ 类别数目&lt;/p&gt;
&lt;p&gt;$A_{ij} =$ 第 $i$ 个区间中第$j$个类别的样本数目&lt;/p&gt;
&lt;p&gt;$E_{ij} = A_{ij}$的期望频率$=\frac{R_i \times C_j}{N}$，$R_i =$第$i$区间的样本数目$= \sum_{j=1}^k A_{ij}$，$C_j = $第$j$个类别的样本数目$= \sum_{i=1}^2 A_{ij}$&lt;/p&gt;
&lt;p&gt;ChiMerge算法包含一个初始化步和一个自底向上的合并过程。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;初始化：将需要离散化的属性的值按从小到大排序，将每个样本作为一个区间&lt;/li&gt;
&lt;li&gt;合并区间
&lt;ol&gt;
&lt;li&gt;计算每对相邻区间的$\chi^2$&lt;/li&gt;
&lt;li&gt;合并具有最小$\chi^2$的相邻区间&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;如果所有相邻区间对的$\chi^2$超过了$\chi^2-threshold$，则停止，否则回到第2步&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;如何确定$\chi^2-threshold$？为此我们需要选择一个想要的显著性水平和自有度，然后通过查表或者公式获得对应的$\chi^2$。其中自由度为&lt;code&gt;类别数目 - 1&lt;/code&gt;，例如，当有3个类别时，自由度为2。&lt;/p&gt;
&lt;p&gt;除了使用$\chi^2-threshold$，还可以指定&lt;code&gt;最小区间数&lt;/code&gt;和&lt;code&gt;最大区间数&lt;/code&gt;来确保不会产生太少或者太多的区间。&lt;/p&gt;
&lt;p&gt;在金融风控中，当我们应用ChiMerge时，在初始化时往往有以下操作：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;连续值按升序排列，离散值首先转化为坏客户的占比，然后再按升序排列&lt;/li&gt;
&lt;li&gt;为了减少计算量，对于状态数大于某一阈值（建议为100）的变量，利用等频分箱进行粗分箱&lt;/li&gt;
&lt;li&gt;若有缺失值，则缺失值单独作为一个分箱&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在分箱完后还会做进一步的处理：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于坏客户占比为0或者1的分箱进行合并（一个分箱内不能全为好客户或者坏客户）&lt;/li&gt;
&lt;li&gt;对于样本占比超过95%的箱子进行删除&lt;/li&gt;
&lt;li&gt;检查缺失分箱的坏客户比例是否和非缺失分箱相等，如果相等，进行合并&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;小结-1&#34;&gt;小结&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;分箱可以有效处理缺失值和异常值&lt;/li&gt;
&lt;li&gt;分箱后数据和模型会更稳定&lt;/li&gt;
&lt;li&gt;分箱可以简化逻辑回归模型，降低过拟合风险，提高泛化能力&lt;/li&gt;
&lt;li&gt;分箱将特征统一变换为类别型变量&lt;/li&gt;
&lt;li&gt;分箱后变量才可以使用标准的评分卡格式&lt;/li&gt;
&lt;/ol&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;阈值的选择需要根据实际情况确定。 &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>RFM模型及实践</title>
      <link>https://keris.github.io/zh/post/what-is-rfm-model/</link>
      <pubDate>Wed, 26 Feb 2020 15:41:30 +0800</pubDate>
      <guid>https://keris.github.io/zh/post/what-is-rfm-model/</guid>
      <description>&lt;p&gt;RFM是一种用于分析客户价值的方法，常用于营销。其中RFM代表三个维度：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;R&lt;/strong&gt;ecency 表示最近一次客户购买的时间&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;F&lt;/strong&gt;requency 表示在统计周期内客户购买的次数&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;M&lt;/strong&gt;onetary Value 表示统计周期内客户消费的总金额&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;接下来，我们使用RFM模型分析一个真实的&lt;a href=&#34;https://www.kaggle.com/carrie1/ecommerce-data#data.csv&#34;&gt;在线购物数据&lt;/a&gt;。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Import libraries
import pandas as pd
import matplotlib.pyplot as plt
import squarify
from datetime import timedelta
import seaborn as sns
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Read dataset
online = pd.read_csv(&#39;data.csv&#39;, encoding=&#39;ISO-8859-1&#39;)
online.head()
&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/style&gt;&lt;/p&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;InvoiceNo&lt;/th&gt;
      &lt;th&gt;StockCode&lt;/th&gt;
      &lt;th&gt;Description&lt;/th&gt;
      &lt;th&gt;Quantity&lt;/th&gt;
      &lt;th&gt;InvoiceDate&lt;/th&gt;
      &lt;th&gt;UnitPrice&lt;/th&gt;
      &lt;th&gt;CustomerID&lt;/th&gt;
      &lt;th&gt;Country&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;536365&lt;/td&gt;
      &lt;td&gt;85123A&lt;/td&gt;
      &lt;td&gt;WHITE HANGING HEART T-LIGHT HOLDER&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;12/1/2010 8:26&lt;/td&gt;
      &lt;td&gt;2.55&lt;/td&gt;
      &lt;td&gt;17850.0&lt;/td&gt;
      &lt;td&gt;United Kingdom&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;536365&lt;/td&gt;
      &lt;td&gt;71053&lt;/td&gt;
      &lt;td&gt;WHITE METAL LANTERN&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;12/1/2010 8:26&lt;/td&gt;
      &lt;td&gt;3.39&lt;/td&gt;
      &lt;td&gt;17850.0&lt;/td&gt;
      &lt;td&gt;United Kingdom&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;536365&lt;/td&gt;
      &lt;td&gt;84406B&lt;/td&gt;
      &lt;td&gt;CREAM CUPID HEARTS COAT HANGER&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;12/1/2010 8:26&lt;/td&gt;
      &lt;td&gt;2.75&lt;/td&gt;
      &lt;td&gt;17850.0&lt;/td&gt;
      &lt;td&gt;United Kingdom&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;536365&lt;/td&gt;
      &lt;td&gt;84029G&lt;/td&gt;
      &lt;td&gt;KNITTED UNION FLAG HOT WATER BOTTLE&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;12/1/2010 8:26&lt;/td&gt;
      &lt;td&gt;3.39&lt;/td&gt;
      &lt;td&gt;17850.0&lt;/td&gt;
      &lt;td&gt;United Kingdom&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;536365&lt;/td&gt;
      &lt;td&gt;84029E&lt;/td&gt;
      &lt;td&gt;RED WOOLLY HOTTIE WHITE HEART.&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;12/1/2010 8:26&lt;/td&gt;
      &lt;td&gt;3.39&lt;/td&gt;
      &lt;td&gt;17850.0&lt;/td&gt;
      &lt;td&gt;United Kingdom&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;online.dtypes
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;InvoiceNo       object
StockCode       object
Description     object
Quantity         int64
InvoiceDate     object
UnitPrice      float64
CustomerID     float64
Country         object
dtype: object
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Convert InvoiceDate from object to datetime format
online[&#39;InvoiceDate&#39;] = pd.to_datetime(online[&#39;InvoiceDate&#39;])
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;online.dtypes
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;InvoiceNo              object
StockCode              object
Description            object
Quantity                int64
InvoiceDate    datetime64[ns]
UnitPrice             float64
CustomerID            float64
Country                object
dtype: object
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Check how many rows and columns
online.shape
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;(541909, 8)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Count transactions that don&#39;t have a customer id
print(&#39;{:,} transactions don\&#39;t have a customer id&#39;
     .format(online[online.CustomerID.isnull()].shape[0]))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;135,080 transactions don&#39;t have a customer id
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Check invoice date range
print(&#39;Transactions timeframe from {} to {}&#39;
     .format(online.InvoiceDate.min(), online.InvoiceDate.max()))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Transactions timeframe from 2010-12-01 08:26:00 to 2011-12-09 12:50:00
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Drop NA values from online
online.dropna(inplace=True)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Group data by CustomerID

# Create TotalSum column for online dataset
online[&#39;TotalSum&#39;] = online[&#39;Quantity&#39;] * online[&#39;UnitPrice&#39;]

# Create snapshot date
snapshot_date = online.InvoiceDate.max() + timedelta(days=1)
print(snapshot_date)

# Group by CustomerID
data = online.groupby([&#39;CustomerID&#39;]).agg({
    &#39;InvoiceDate&#39;: lambda x: (snapshot_date - x.max()).days,
    &#39;InvoiceNo&#39;: &#39;count&#39;,
    &#39;TotalSum&#39;: &#39;sum&#39;
})

data.rename(columns={&#39;InvoiceDate&#39;: &#39;Recency&#39;,
                     &#39;InvoiceNo&#39;: &#39;Frequency&#39;,
                     &#39;TotalSum&#39;: &#39;MonetaryValue&#39;}, inplace=True)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;2011-12-10 12:50:00
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Peek first 5 rows
data.head()
&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/style&gt;&lt;/p&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Recency&lt;/th&gt;
      &lt;th&gt;Frequency&lt;/th&gt;
      &lt;th&gt;MonetaryValue&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;CustomerID&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;12346.0&lt;/th&gt;
      &lt;td&gt;326&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;0.00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;12347.0&lt;/th&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;182&lt;/td&gt;
      &lt;td&gt;4310.00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;12348.0&lt;/th&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;31&lt;/td&gt;
      &lt;td&gt;1797.24&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;12349.0&lt;/th&gt;
      &lt;td&gt;19&lt;/td&gt;
      &lt;td&gt;73&lt;/td&gt;
      &lt;td&gt;1757.55&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;12350.0&lt;/th&gt;
      &lt;td&gt;310&lt;/td&gt;
      &lt;td&gt;17&lt;/td&gt;
      &lt;td&gt;334.40&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Check how many rows and columns
data.shape
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;(4372, 3)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在这里我们可以看到，根据CutomerID进行分组后，我们聚合生成了每个客户最近一次购买的时间，购买频率和消费额度，共4372条记录。接下来，我们需要对这三个维度进行打分，这可以通过&lt;code&gt;.qcut()&lt;/code&gt;来进行。但在此之前，我们先看一看特征的分布情况。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Plot RFM distributions
plt.figure(figsize=(12,10))

# Plot distribution of R
plt.subplot(3, 1, 1)
sns.distplot(data[&#39;Recency&#39;])

# Plot distribution of F
plt.subplot(3, 1, 2)
sns.distplot(data[&#39;Frequency&#39;])

# Plot distribution of M
plt.subplot(3, 1, 3)
sns.distplot(data[&#39;MonetaryValue&#39;])
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;matplotlib.axes._subplots.AxesSubplot at 0x1199779b0&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_13_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Calculate R and F groups

# Create labels for Recency and Frequency
r_labels = range(4, 0, -1)
f_labels = range(1, 5)

# Assign these labels to 4 equal percentil groups
r_groups = pd.qcut(data[&#39;Recency&#39;], q=4, labels=r_labels)

f_groups = pd.qcut(data[&#39;Frequency&#39;], q=4, labels=f_labels)

# Create new columns R and F
data = data.assign(R=r_groups.values, F=f_groups.values)
data.head()
&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/style&gt;&lt;/p&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Recency&lt;/th&gt;
      &lt;th&gt;Frequency&lt;/th&gt;
      &lt;th&gt;MonetaryValue&lt;/th&gt;
      &lt;th&gt;R&lt;/th&gt;
      &lt;th&gt;F&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;CustomerID&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;12346.0&lt;/th&gt;
      &lt;td&gt;326&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;0.00&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;12347.0&lt;/th&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;182&lt;/td&gt;
      &lt;td&gt;4310.00&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;12348.0&lt;/th&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;31&lt;/td&gt;
      &lt;td&gt;1797.24&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;12349.0&lt;/th&gt;
      &lt;td&gt;19&lt;/td&gt;
      &lt;td&gt;73&lt;/td&gt;
      &lt;td&gt;1757.55&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;12350.0&lt;/th&gt;
      &lt;td&gt;310&lt;/td&gt;
      &lt;td&gt;17&lt;/td&gt;
      &lt;td&gt;334.40&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Create labels form MonetaryValue
m_labels = range(1, 5)
m_groups = pd.qcut(data[&#39;MonetaryValue&#39;], q=4, labels=m_labels)
data = data.assign(M=m_groups.values)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data.head()
&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/style&gt;&lt;/p&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Recency&lt;/th&gt;
      &lt;th&gt;Frequency&lt;/th&gt;
      &lt;th&gt;MonetaryValue&lt;/th&gt;
      &lt;th&gt;R&lt;/th&gt;
      &lt;th&gt;F&lt;/th&gt;
      &lt;th&gt;M&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;CustomerID&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;12346.0&lt;/th&gt;
      &lt;td&gt;326&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;0.00&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;12347.0&lt;/th&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;182&lt;/td&gt;
      &lt;td&gt;4310.00&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;12348.0&lt;/th&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;31&lt;/td&gt;
      &lt;td&gt;1797.24&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;12349.0&lt;/th&gt;
      &lt;td&gt;19&lt;/td&gt;
      &lt;td&gt;73&lt;/td&gt;
      &lt;td&gt;1757.55&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;12350.0&lt;/th&gt;
      &lt;td&gt;310&lt;/td&gt;
      &lt;td&gt;17&lt;/td&gt;
      &lt;td&gt;334.40&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Concat RFM quartile values to create RFM segments
def join_rfm(x):
    return str(x[&#39;R&#39;]) + str(x[&#39;F&#39;]) + str(x[&#39;M&#39;])

data[&#39;RFM_segment_concat&#39;] = data.apply(join_rfm, axis=1)
rfm = data
rfm.head()
&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/style&gt;&lt;/p&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Recency&lt;/th&gt;
      &lt;th&gt;Frequency&lt;/th&gt;
      &lt;th&gt;MonetaryValue&lt;/th&gt;
      &lt;th&gt;R&lt;/th&gt;
      &lt;th&gt;F&lt;/th&gt;
      &lt;th&gt;M&lt;/th&gt;
      &lt;th&gt;RFM_segment_concat&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;CustomerID&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;12346.0&lt;/th&gt;
      &lt;td&gt;326&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;0.00&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;111&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;12347.0&lt;/th&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;182&lt;/td&gt;
      &lt;td&gt;4310.00&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;444&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;12348.0&lt;/th&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;31&lt;/td&gt;
      &lt;td&gt;1797.24&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;224&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;12349.0&lt;/th&gt;
      &lt;td&gt;19&lt;/td&gt;
      &lt;td&gt;73&lt;/td&gt;
      &lt;td&gt;1757.55&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;334&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;12350.0&lt;/th&gt;
      &lt;td&gt;310&lt;/td&gt;
      &lt;td&gt;17&lt;/td&gt;
      &lt;td&gt;334.40&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;112&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Count num of unique segments
rfm_count_unique = rfm.groupby(&#39;RFM_segment_concat&#39;)[&#39;RFM_segment_concat&#39;].nunique()
print(rfm_count_unique.sum())
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;62
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;以上结果显示，将RFM连接在一起这种方法共形成62个划分，但划分太多了不能用于实际应用。下面我们尝试将这三个值相加。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Calculate RFM_Score
rfm[&#39;RFM_Score&#39;] = rfm[[&#39;R&#39;, &#39;F&#39;, &#39;M&#39;]].sum(axis=1)
print(rfm[&#39;RFM_Score&#39;].head())
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;CustomerID
12346.0     3.0
12347.0    12.0
12348.0     8.0
12349.0    10.0
12350.0     4.0
Name: RFM_Score, dtype: float64
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Define rfm_level function
def rfm_level(df):
    if df[&#39;RFM_Score&#39;] &amp;gt;= 9:
        return &#39;Can\&#39;t Loose Them&#39;
    elif ((df[&#39;RFM_Score&#39;] &amp;gt;= 8) and (df[&#39;RFM_Score&#39;] &amp;lt; 9)):
        return &#39;Champions&#39;
    elif ((df[&#39;RFM_Score&#39;] &amp;gt;= 7) and (df[&#39;RFM_Score&#39;] &amp;lt; 8)):
        return &#39;Loyal&#39;
    elif ((df[&#39;RFM_Score&#39;] &amp;gt;= 6) and (df[&#39;RFM_Score&#39;] &amp;lt; 7)):
        return &#39;Potential&#39;
    elif ((df[&#39;RFM_Score&#39;] &amp;gt;= 5) and (df[&#39;RFM_Score&#39;] &amp;lt; 6)):
        return &#39;Promising&#39;
    elif ((df[&#39;RFM_Score&#39;] &amp;gt;= 4) and (df[&#39;RFM_Score&#39;] &amp;lt; 5)):
        return &#39;Needs Attention&#39;
    else:
        return &#39;Require Activation&#39;

# Create a new variable RFM_Level
rfm[&#39;RFM_Level&#39;] = rfm.apply(rfm_level, axis=1)

rfm.head()
&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/style&gt;&lt;/p&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Recency&lt;/th&gt;
      &lt;th&gt;Frequency&lt;/th&gt;
      &lt;th&gt;MonetaryValue&lt;/th&gt;
      &lt;th&gt;R&lt;/th&gt;
      &lt;th&gt;F&lt;/th&gt;
      &lt;th&gt;M&lt;/th&gt;
      &lt;th&gt;RFM_segment_concat&lt;/th&gt;
      &lt;th&gt;RFM_Score&lt;/th&gt;
      &lt;th&gt;RFM_Level&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;CustomerID&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;12346.0&lt;/th&gt;
      &lt;td&gt;326&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;0.00&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;111&lt;/td&gt;
      &lt;td&gt;3.0&lt;/td&gt;
      &lt;td&gt;Require Activation&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;12347.0&lt;/th&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;182&lt;/td&gt;
      &lt;td&gt;4310.00&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;444&lt;/td&gt;
      &lt;td&gt;12.0&lt;/td&gt;
      &lt;td&gt;Can&#39;t Loose Them&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;12348.0&lt;/th&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;31&lt;/td&gt;
      &lt;td&gt;1797.24&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;224&lt;/td&gt;
      &lt;td&gt;8.0&lt;/td&gt;
      &lt;td&gt;Champions&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;12349.0&lt;/th&gt;
      &lt;td&gt;19&lt;/td&gt;
      &lt;td&gt;73&lt;/td&gt;
      &lt;td&gt;1757.55&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;334&lt;/td&gt;
      &lt;td&gt;10.0&lt;/td&gt;
      &lt;td&gt;Can&#39;t Loose Them&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;12350.0&lt;/th&gt;
      &lt;td&gt;310&lt;/td&gt;
      &lt;td&gt;17&lt;/td&gt;
      &lt;td&gt;334.40&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;112&lt;/td&gt;
      &lt;td&gt;4.0&lt;/td&gt;
      &lt;td&gt;Needs Attention&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Calculate average values for each RFM_Level, and return a size of each segment
rfm_level_agg = rfm.groupby(&#39;RFM_Level&#39;).agg({
    &#39;Recency&#39;: &#39;mean&#39;,
    &#39;Frequency&#39;: &#39;mean&#39;,
    &#39;MonetaryValue&#39;: [&#39;mean&#39;, &#39;count&#39;]
}).round(1)

# Print the aggregate dataset
print(rfm_level_agg)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;                   Recency Frequency MonetaryValue
                      mean      mean          mean count
RFM_Level
Can&#39;t Loose Them      25.2     195.1        4130.3  1690
Champions             62.7      57.0         974.7   467
Loyal                 78.8      39.7         724.2   447
Needs Attention      174.5      13.9         227.1   391
Potential             94.3      28.5         491.8   468
Promising            153.0      21.2         346.8   517
Require Activation   264.8       7.8         109.1   392
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;从以上结果我们可以看到，约60%的客户属于优质客户（前三类用户）。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Visualize segments
rfm_level_agg.columns = rfm_level_agg.columns.droplevel()
rfm_level_agg.columns = [&#39;RecencyMean&#39;, &#39;FrequencyMean&#39;, &#39;MonetaryMean&#39;, &#39;Count&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Create our plot and resize it
fig = plt.gcf()
ax = fig.add_subplot()
fig.set_size_inches(16, 9)

squarify.plot(sizes=rfm_level_agg[&#39;Count&#39;], label=list(rfm_level_agg.index), alpha=.6)
plt.title(&#39;RFM Segments&#39;, fontsize=18, fontweight=&#39;bold&#39;)
plt.axis(&#39;off&#39;)
plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_25_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>逻辑回归（Logistic Regression）</title>
      <link>https://keris.github.io/zh/post/logistic-regression/</link>
      <pubDate>Tue, 14 Jan 2020 16:47:22 +0800</pubDate>
      <guid>https://keris.github.io/zh/post/logistic-regression/</guid>
      <description>&lt;h2&gt;目录&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#术语&#34;&gt;术语&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#logistic-function&#34;&gt;Logistic function&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#odds&#34;&gt;Odds&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#logit-function&#34;&gt;Logit function&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#逻辑回归&#34;&gt;逻辑回归&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#代价函数求导&#34;&gt;代价函数求导&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;h2 id=&#34;术语&#34;&gt;术语&lt;/h2&gt;
&lt;p&gt;逻辑回归涉及到以下术语：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Logistic function&lt;/li&gt;
&lt;li&gt;Odds&lt;/li&gt;
&lt;li&gt;Logit&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;logistic-function&#34;&gt;Logistic function&lt;/h3&gt;
&lt;p&gt;逻辑回归中的 &lt;em&gt;Logistic&lt;/em&gt; 正是出于 &lt;em&gt;Logistic function&lt;/em&gt; ，它是一种 &lt;em&gt;sigmoid function&lt;/em&gt; ，其接受任意实值，输出一个0到1之间的值。
&lt;em&gt;标准的&lt;/em&gt; logistic funtion 定义如下：&lt;/p&gt;
&lt;p&gt;$$\sigma(z) = \frac{e^z}{e^z + 1} = \frac{1}{1 + e^{-z}}$$&lt;/p&gt;
&lt;p&gt;如下是它在区间$[-6, 6]$之间的图像：&lt;/p&gt;
&lt;p&gt;&lt;a title=&#34;logistic function curve&#34; href=&#34;https://commons.wikimedia.org/wiki/File:Logistic-curve.svg&#34;&gt;&lt;img width=&#34;512&#34; alt=&#34;Logistic-curve&#34; src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/512px-Logistic-curve.svg.png&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;在逻辑回归中，我们使用对数几率（log odds），&lt;strong&gt;并假定它是输入特征的线性组合&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;$$z = \ln \frac{p(x)}{1 - p(x)}= \theta_0 + \theta_1 x_1 + \theta_2 x_2 = \theta^T \cdot x$$&lt;/p&gt;
&lt;p&gt;由上式我们可以得到，&lt;/p&gt;
&lt;p&gt;$$p(x) = \sigma(z) = \frac{1}{1 + e^{-\theta^T \cdot x}}$$&lt;/p&gt;
&lt;p&gt;在逻辑回归模型中，这里的 $p(x)$ 为因变量在成功情形下的概率，即 $p(y=1 \mid x)$。&lt;/p&gt;
&lt;h3 id=&#34;odds&#34;&gt;Odds&lt;/h3&gt;
&lt;p&gt;如果 $p$ 表示一个事件发生的概率，那么odds定义为&lt;/p&gt;
&lt;p&gt;$$\text{odds} = \frac{p}{1 - p}$$
也就是说，odds为发生的概率除以不发生的概率，亦可以说为成功的概率除以失败的概率。&lt;/p&gt;
&lt;h3 id=&#34;logit-function&#34;&gt;Logit function&lt;/h3&gt;
&lt;p&gt;Logit为Log odds, logit function 定义为 logistic function的逆，即 $g = \sigma^{-1}$。显而易见，我们有&lt;/p&gt;
&lt;p&gt;$$g(p(x)) = \sigma_{-1}(p(x)) = \text{logit}\,p(x) = \ln(\frac{p(x)}{1 - p(x)}) = \theta^T \cdot x$$&lt;/p&gt;
&lt;h2 id=&#34;逻辑回归&#34;&gt;逻辑回归&lt;/h2&gt;
&lt;p&gt;逻辑回归是一个重要的机器学习算法，其目标是基于给定的数据$x$输出随机变量$y$为0或1的概率。&lt;/p&gt;
&lt;p&gt;考虑由$\theta$参数化的线性模型，&lt;/p&gt;
&lt;p&gt;$$h_\theta(x) = \frac{1}{1 + e^{-\theta^T \cdot x}} = \text{Pr}(y = 1 \mid x;\theta)$$&lt;/p&gt;
&lt;p&gt;从而，$\text{Pr}(y=0 \mid x;\theta) = 1 - h_\theta(x)$。&lt;/p&gt;
&lt;p&gt;因为$y \in \{0, 1 \}$，我们有&lt;/p&gt;
&lt;p&gt;$$\text{Pr}(y \mid x;\theta) = h_\theta(x)^y (1 - h_\theta(x))^{1 - y}
$$&lt;/p&gt;
&lt;p&gt;似然函数为&lt;/p&gt;
&lt;p&gt;$$\begin{aligned} L(\theta \mid x) &amp;amp;= \Pr(Y\mid X;\theta) \\&lt;br&gt;
&amp;amp;= \prod_i \Pr(y^{(i)} \mid x^{(i)};\theta) \\&lt;br&gt;
&amp;amp;= \prod_i h_\theta(x^{(i)})^{y^{(i)}}(1-h_\theta(x^{(i)}))^{1-y^{(i)}} \end{aligned}$$&lt;/p&gt;
&lt;p&gt;一般地，我们最大化对数似然函数，&lt;/p&gt;
&lt;p&gt;$$\log L(\theta \mid x) = \sum_{i=1}^{m}\log \Pr(y^{(i)} \mid x^{(i)};\theta)$$&lt;/p&gt;
&lt;p&gt;定义代价函数如下：&lt;/p&gt;
&lt;p&gt;$$J(\theta) = -\frac{1}{m} \log L(\theta \mid x) = -\frac{1}{m} \sum_i^m (y^{(i)} \log h_\theta(x^{(i)}) + (1 - y^{(i)})(1 - h_\theta(x^{(i)})))$$&lt;/p&gt;
&lt;p&gt;容易看到，我们最大化对数似然函数就是最小化代价函数 $J(\theta)$。在机器学习中，我们使用梯度下降最小化代价函数。&lt;/p&gt;
&lt;h3 id=&#34;代价函数求导&#34;&gt;代价函数求导&lt;/h3&gt;
&lt;p&gt;下面我们对代价函数$J(\theta)$对$\theta$进行求导，我们先考虑在一个样本上的代价函数&lt;/p&gt;
&lt;p&gt;$$J_1(\theta) = -y \log h_\theta(x) - (1 - y)(1 - h_\theta(x))$$&lt;/p&gt;
&lt;p&gt;现在对$J_1(\theta)$对$\theta$进行求导：&lt;/p&gt;
&lt;p&gt;注意到$\frac{d\sigma(z)}{dz} = \sigma(z) (1 - \sigma(z))$, 我们有&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}\frac{\partial}{\partial \theta_j} J_1(\theta) &amp;amp;= -y \frac{1}{h_\theta(x)} h_\theta(x) (1 - h_\theta(x)) x_j - (1 - y) \frac{1}{1 - h_\theta(x)} (-1) h_\theta(x) (1 - h_\theta(x)) x_j \\ &amp;amp;= (h_\theta(x) - y) x_j\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;有了以上结果，我们有&lt;/p&gt;
&lt;p&gt;$$\frac{\partial}{\partial \theta_j} J(\theta) = \frac{1}{m}\sum_i^m [h_\theta(x^{(i)}) - y^{(i)}]x_j^{(i)}$$&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>更改git提交中的作者和邮件信息</title>
      <link>https://keris.github.io/zh/post/change-author-name-email/</link>
      <pubDate>Thu, 07 Nov 2019 17:47:23 +0800</pubDate>
      <guid>https://keris.github.io/zh/post/change-author-name-email/</guid>
      <description>&lt;p&gt;在git的日常使用中更改提交的作者名和邮箱是一个十分常见的操作。例如，当你克隆了一个项目，如果你没有进行任何设置，此时提交的作者和邮件将使用全局选项，这可能不是你所要的。&lt;/p&gt;
&lt;p&gt;通过本文你将了解：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如何配置git使用的提交者用户名和邮箱&lt;/li&gt;
&lt;li&gt;如何更改最近一次提交的作者名和邮件&lt;/li&gt;
&lt;li&gt;批量更改提交的作者名和邮件&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;配置提交者用户名和邮箱&#34;&gt;配置提交者用户名和邮箱&lt;/h2&gt;
&lt;p&gt;你有两种方式进行设置，一是全局配置，二是为每个repo单独配置。&lt;/p&gt;
&lt;h3 id=&#34;全局地更改提交者用户名和邮箱&#34;&gt;全局地更改提交者用户名和邮箱&lt;/h3&gt;
&lt;p&gt;使用&lt;code&gt;git config&lt;/code&gt;并&lt;code&gt;--global&lt;/code&gt;选项进行全局设置，如下所示：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;$ git config --global user.name &amp;quot;Du Liqiang&amp;quot;
$ git config --global user.email &amp;quot;dlq137@gmail.com&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;设置完毕后，后续的提交将使用以上提供的信息。&lt;/p&gt;
&lt;h3 id=&#34;为某个repo单独配置&#34;&gt;为某个repo单独配置&lt;/h3&gt;
&lt;p&gt;全局选项可能并不适用于某个repo，此时就需要单独设置，使用&lt;code&gt;git config&lt;/code&gt;但省略&lt;code&gt;--global&lt;/code&gt;选项，如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;$ git config user.name &amp;quot;Du Liqiang&amp;quot;
$ git config user.email &amp;quot;dlq137@gmail.com&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里的设置将覆盖全局选项，并且只应用于当前的repo。&lt;/p&gt;
&lt;h2 id=&#34;更改最近一次提交的作者用户名和邮箱&#34;&gt;更改最近一次提交的作者用户名和邮箱&lt;/h2&gt;
&lt;p&gt;如果你刚做了一次提交，发现用户名和邮箱并不是所要的，你可以使用&lt;code&gt;--amend&lt;/code&gt;选项重新提交：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;$ git commit --amend --author=&amp;quot;Du Liqiang &amp;lt;dlq137@gmail.com&amp;gt;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;更改多次提交的作者用户名和邮箱&#34;&gt;更改多次提交的作者用户名和邮箱&lt;/h2&gt;
&lt;p&gt;这个时候我们需要借助强大的&lt;code&gt;rebase&lt;/code&gt;命令，首先我们找到上一次“好”的提交&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;，并假设其提交hash为&lt;code&gt;0ad14fa5&lt;/code&gt;，执行：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;$ git rebase -i -p 0ad14fa5
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;此时我们会进入一个编辑器，将那些需要编辑的提交全标记为&lt;code&gt;edit&lt;/code&gt;，接下来git会指导你完成每次提交的编辑，你需要做的就是执行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ git commit --amend --author=&amp;quot;Du Liqiang &amp;lt;dlq137@gmail.com&amp;gt; --no-edit
$ git rebase --continue
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;使用git-filter-branch批量更改&#34;&gt;使用git filter-branch批量更改&lt;/h2&gt;
&lt;p&gt;除了以上交互式的更改方法，另一种方法是借助git的&lt;code&gt;filter-branch&lt;/code&gt;命令，其允许你使用一个script批量处理大量的提交。&lt;/p&gt;
&lt;p&gt;如下命令筛选提交邮箱为WRONG_EMAIL的提交，并将其用户名和邮箱分别设置为NEW_NAME和NEW_EMAIL对应的值。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;$ git filter-branch --env-filter &#39;
WRONG_EMAIL=&amp;quot;wrong@example.com&amp;quot;
NEW_NAME=&amp;quot;New Name Value&amp;quot;
NEW_EMAIL=&amp;quot;correct@example.com&amp;quot;

if [ &amp;quot;$GIT_COMMITTER_EMAIL&amp;quot; = &amp;quot;$WRONG_EMAIL&amp;quot; ]
then
    export GIT_COMMITTER_NAME=&amp;quot;$NEW_NAME&amp;quot;
    export GIT_COMMITTER_EMAIL=&amp;quot;$NEW_EMAIL&amp;quot;
fi
if [ &amp;quot;$GIT_AUTHOR_EMAIL&amp;quot; = &amp;quot;$WRONG_EMAIL&amp;quot; ]
then
    export GIT_AUTHOR_NAME=&amp;quot;$NEW_NAME&amp;quot;
    export GIT_AUTHOR_EMAIL=&amp;quot;$NEW_EMAIL&amp;quot;
fi
&#39; --tag-name-filter cat -- --branches --tags
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.git-tower.com/learn/git/faq/change-author-name-email&#34;&gt;https://www.git-tower.com/learn/git/faq/change-author-name-email&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;该次提交之前的提交具有正确的用户名和邮箱，其后的需要进行更改。 &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;</description>
    </item>
    
  </channel>
</rss>
